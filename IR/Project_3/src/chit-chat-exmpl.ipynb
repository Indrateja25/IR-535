{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc36d466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T03:24:07.443212Z",
     "start_time": "2023-11-22T03:24:07.437653Z"
    }
   },
   "outputs": [],
   "source": [
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ListTrainer\n",
    "from chatterbot.trainers import ChatterBotCorpusTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a08b6090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T03:20:01.325823Z",
     "start_time": "2023-11-22T03:20:01.306765Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/indra25/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to /Users/indra25/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/indra25/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<chatterbot.chatterbot.ChatBot at 0x7fb970081be0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot = ChatBot(\"IR-Project3\",\n",
    "                    storage_adapter='chatterbot.storage.SQLStorageAdapter',\n",
    "                    logic_adapters=[\n",
    "                                        'chatterbot.logic.MathematicalEvaluation',\n",
    "                                        'chatterbot.logic.TimeLogicAdapter'\n",
    "                                    ],\n",
    "                    database_uri='sqlite:///database.sqlite3'\n",
    "                 )\n",
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d49cad2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T03:21:01.474325Z",
     "start_time": "2023-11-22T03:20:22.239756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "The current time is 10:20 PM\n",
      "i didn't ask time\n",
      "The current time is 10:20 PM\n",
      "stop\n",
      "The current time is 10:20 PM\n",
      "quit\n",
      "The current time is 10:20 PM\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        bot_input = chatbot.get_response(input())\n",
    "        print(bot_input)\n",
    "\n",
    "    except(KeyboardInterrupt, EOFError, SystemExit):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ac99337",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T03:22:14.474530Z",
     "start_time": "2023-11-22T03:22:14.450296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List Trainer: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "trainer = ListTrainer(chatbot)\n",
    "trainer.train([\n",
    "    'How are you?',\n",
    "    'I am good.',\n",
    "    'That is good to hear.',\n",
    "    'Thank you',\n",
    "    'You are welcome.',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6947259f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T03:22:30.642317Z",
     "start_time": "2023-11-22T03:22:16.560610Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How are you?\n",
      "The current time is 10:22 PM\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        bot_input = chatbot.get_response(input())\n",
    "        print(bot_input)\n",
    "\n",
    "    except(KeyboardInterrupt, EOFError, SystemExit):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6c7223d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T03:25:46.877131Z",
     "start_time": "2023-11-22T03:25:45.846806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ai.yml: [####################] 100%\n",
      "Training botprofile.yml: [####################] 100%\n",
      "Training computers.yml: [####################] 100%\n",
      "Training conversations.yml: [####################] 100%\n",
      "Training emotion.yml: [####################] 100%\n",
      "Training food.yml: [####################] 100%\n",
      "Training gossip.yml: [####################] 100%\n",
      "Training greetings.yml: [####################] 100%\n",
      "Training health.yml: [####################] 100%\n",
      "Training history.yml: [####################] 100%\n",
      "Training humor.yml: [####################] 100%\n",
      "Training literature.yml: [####################] 100%\n",
      "Training money.yml: [####################] 100%\n",
      "Training movies.yml: [####################] 100%\n",
      "Training politics.yml: [####################] 100%\n",
      "Training psychology.yml: [####################] 100%\n",
      "Training science.yml: [####################] 100%\n",
      "Training sports.yml: [####################] 100%\n",
      "Training trivia.yml: [####################] 100%\n",
      "Training greetings.yml: [####################] 100%\n",
      "Training conversations.yml: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "trainer = ChatterBotCorpusTrainer(chatbot)\n",
    "trainer.train(\n",
    "                \"chatterbot.corpus.english\",\n",
    "                \"chatterbot.corpus.english.greetings\",\n",
    "                \"chatterbot.corpus.english.conversations\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cac4e181",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-22T03:25:48.785935Z",
     "start_time": "2023-11-22T03:25:48.751378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current time is 10:25 PM\n"
     ]
    }
   ],
   "source": [
    "response = chatbot.get_response('hello')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf97a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76a2959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad3c4be8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T02:29:04.060405Z",
     "start_time": "2023-11-28T02:29:03.287719Z"
    }
   },
   "outputs": [],
   "source": [
    "import openllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec69ccc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T02:34:08.455174Z",
     "start_time": "2023-11-28T02:34:08.382706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HTTPClient address=http://0.0.0.0:3000/ timeout=Timeout(timeout=30) api_version=v1 verify=True>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = openllm.client.HTTPClient('http://0.0.0.0:3000/')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaf773af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T02:34:11.609301Z",
     "start_time": "2023-11-28T02:34:09.221069Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HTTPStatusError' object has no attribute 'message'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/openllm_client/_shim.py:412\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, response_cls, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    411\u001b[0m   logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl, response\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m.\u001b[39mreason_phrase)\n\u001b[0;32m--> 412\u001b[0m   \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/httpx/_models.py:758\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    757\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 758\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Server error '500 Internal Server Error' for url 'http://0.0.0.0:3000/v1/generate'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/openllm_client/_shim.py:412\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, response_cls, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    411\u001b[0m   logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl, response\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m.\u001b[39mreason_phrase)\n\u001b[0;32m--> 412\u001b[0m   \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/httpx/_models.py:758\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    757\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 758\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Server error '500 Internal Server Error' for url 'http://0.0.0.0:3000/v1/generate'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/openllm_client/_shim.py:412\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, response_cls, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    411\u001b[0m   logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m]: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl, response\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m.\u001b[39mreason_phrase)\n\u001b[0;32m--> 412\u001b[0m   \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/httpx/_models.py:758\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    757\u001b[0m message \u001b[38;5;241m=\u001b[39m message\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m, error_type\u001b[38;5;241m=\u001b[39merror_type)\n\u001b[0;32m--> 758\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTPStatusError(message, request\u001b[38;5;241m=\u001b[39mrequest, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPStatusError\u001b[0m: Server error '500 Internal Server Error' for url 'http://0.0.0.0:3000/v1/generate'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhat is a language model?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m response\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/openllm_client/_http.py:70\u001b[0m, in \u001b[0;36mHTTPClient.query\u001b[0;34m(self, prompt, **attrs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mattrs):\n\u001b[0;32m---> 70\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/openllm_client/_http.py:90\u001b[0m, in \u001b[0;36mHTTPClient.generate\u001b[0;34m(self, prompt, llm_config, stop, adapter_name, timeout, verify, **attrs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m   llm_config \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mattrs}\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_version\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/generate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m  \u001b[49m\u001b[43mresponse_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mllm_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m  \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_retries\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_retries\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/openllm_client/_shim.py:478\u001b[0m, in \u001b[0;36mClient._post\u001b[0;34m(self, path, response_cls, json, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    477\u001b[0m   options \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m  \u001b[49m\u001b[43mresponse_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRequestOptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/openllm_client/_shim.py:390\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, response_cls, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    382\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    383\u001b[0m   response_cls: \u001b[38;5;28mtype\u001b[39m[Response],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    388\u001b[0m   stream_cls: \u001b[38;5;28mtype\u001b[39m[_Stream] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    389\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Response \u001b[38;5;241m|\u001b[39m _Stream:\n\u001b[0;32m--> 390\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/openllm_client/_shim.py:415\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, response_cls, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    414\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(exc\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m      \u001b[49m\u001b[43mresponse_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m   \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the completed response\u001b[39;00m\n\u001b[1;32m    419\u001b[0m   exc\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/openllm_client/_shim.py:449\u001b[0m, in \u001b[0;36mClient._retry_request\u001b[0;34m(self, response_cls, options, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# In synchronous thread we are blocking the thread. Depends on how users want to do this downstream.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/openllm_client/_shim.py:415\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, response_cls, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    414\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(exc\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m      \u001b[49m\u001b[43mresponse_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m   \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the completed response\u001b[39;00m\n\u001b[1;32m    419\u001b[0m   exc\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/openllm_client/_shim.py:449\u001b[0m, in \u001b[0;36mClient._retry_request\u001b[0;34m(self, response_cls, options, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# In synchronous thread we are blocking the thread. Depends on how users want to do this downstream.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/openllm_client/_shim.py:420\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, response_cls, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    418\u001b[0m   \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the completed response\u001b[39;00m\n\u001b[1;32m    419\u001b[0m   exc\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 420\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[43mexc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage\u001b[49m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException:\n\u001b[1;32m    422\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HTTPStatusError' object has no attribute 'message'"
     ]
    }
   ],
   "source": [
    "query = 'what is a language model?'\n",
    "response = client.query(query)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23c1216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad041186",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eca7b21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T02:39:10.306454Z",
     "start_time": "2023-11-28T02:36:30.028178Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is recommended to specify the backend explicitly. Cascading backend might lead to unexpected behaviour.\n",
      "/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "config.json: 100%|██████████████████████████████| 691/691 [00:00<00:00, 180kB/s]\n",
      "tokenizer_config.json: 100%|████████████████████| 685/685 [00:00<00:00, 192kB/s]\n",
      "vocab.json: 100%|████████████████████████████| 899k/899k [00:00<00:00, 9.92MB/s]\n",
      "merges.txt: 100%|████████████████████████████| 456k/456k [00:00<00:00, 37.3MB/s]\n",
      "special_tokens_map.json: 100%|██████████████████| 441/441 [00:00<00:00, 202kB/s]\n",
      "Fetching 7 files:   0%|                                   | 0/7 [00:00<?, ?it/s]\n",
      "generation_config.json: 100%|███████████████████| 137/137 [00:00<00:00, 217kB/s]\u001b[A\n",
      "Fetching 7 files:  29%|███████▋                   | 2/7 [00:00<00:00, 10.30it/s]\n",
      "pytorch_model.bin:   0%|                            | 0.00/5.30G [00:00<?, ?B/s]\u001b[A\n",
      "pytorch_model.bin:   0%|                   | 10.5M/5.30G [00:00<02:56, 30.0MB/s]\u001b[A\n",
      "pytorch_model.bin:   0%|                   | 21.0M/5.30G [00:00<01:52, 46.9MB/s]\u001b[A\n",
      "pytorch_model.bin:   1%|                   | 31.5M/5.30G [00:00<02:34, 34.2MB/s]\u001b[A\n",
      "pytorch_model.bin:   1%|▏                  | 41.9M/5.30G [00:01<02:14, 39.2MB/s]\u001b[A\n",
      "pytorch_model.bin:   1%|▏                  | 52.4M/5.30G [00:01<02:56, 29.7MB/s]\u001b[A\n",
      "pytorch_model.bin:   1%|▏                  | 62.9M/5.30G [00:01<02:34, 34.0MB/s]\u001b[A\n",
      "pytorch_model.bin:   1%|▎                  | 73.4M/5.30G [00:01<02:05, 41.7MB/s]\u001b[A\n",
      "pytorch_model.bin:   2%|▎                  | 83.9M/5.30G [00:02<02:44, 31.7MB/s]\u001b[A\n",
      "pytorch_model.bin:   2%|▎                  | 94.4M/5.30G [00:02<02:10, 39.8MB/s]\u001b[A\n",
      "pytorch_model.bin:   2%|▍                   | 105M/5.30G [00:02<02:21, 36.8MB/s]\u001b[A\n",
      "pytorch_model.bin:   2%|▍                   | 115M/5.30G [00:03<02:04, 41.7MB/s]\u001b[A\n",
      "pytorch_model.bin:   2%|▍                   | 126M/5.30G [00:03<01:49, 47.2MB/s]\u001b[A\n",
      "pytorch_model.bin:   3%|▌                   | 136M/5.30G [00:03<01:53, 45.5MB/s]\u001b[A\n",
      "pytorch_model.bin:   3%|▌                   | 147M/5.30G [00:03<01:39, 51.9MB/s]\u001b[A\n",
      "pytorch_model.bin:   3%|▌                   | 157M/5.30G [00:03<02:03, 41.5MB/s]\u001b[A\n",
      "pytorch_model.bin:   3%|▋                   | 168M/5.30G [00:04<01:50, 46.5MB/s]\u001b[A\n",
      "pytorch_model.bin:   3%|▋                   | 178M/5.30G [00:04<01:36, 53.0MB/s]\u001b[A\n",
      "pytorch_model.bin:   4%|▋                   | 189M/5.30G [00:05<02:52, 29.7MB/s]\u001b[A\n",
      "pytorch_model.bin:   4%|▊                   | 199M/5.30G [00:05<02:18, 36.8MB/s]\u001b[A\n",
      "pytorch_model.bin:   4%|▊                   | 210M/5.30G [00:05<01:57, 43.3MB/s]\u001b[A\n",
      "pytorch_model.bin:   4%|▊                   | 220M/5.30G [00:05<02:10, 38.9MB/s]\u001b[A\n",
      "pytorch_model.bin:   4%|▊                   | 231M/5.30G [00:05<01:50, 46.0MB/s]\u001b[A\n",
      "pytorch_model.bin:   5%|▉                   | 241M/5.30G [00:06<02:34, 32.9MB/s]\u001b[A\n",
      "pytorch_model.bin:   5%|▉                   | 252M/5.30G [00:06<02:16, 37.1MB/s]\u001b[A\n",
      "pytorch_model.bin:   5%|▉                   | 262M/5.30G [00:06<02:20, 35.9MB/s]\u001b[A\n",
      "pytorch_model.bin:   5%|█                   | 273M/5.30G [00:07<02:11, 38.3MB/s]\u001b[A\n",
      "pytorch_model.bin:   5%|█                   | 283M/5.30G [00:07<01:56, 42.9MB/s]\u001b[A\n",
      "pytorch_model.bin:   6%|█                   | 294M/5.30G [00:07<02:03, 40.7MB/s]\u001b[A\n",
      "pytorch_model.bin:   6%|█▏                  | 304M/5.30G [00:07<02:17, 36.3MB/s]\u001b[A\n",
      "pytorch_model.bin:   6%|█▏                  | 315M/5.30G [00:08<02:13, 37.5MB/s]\u001b[A\n",
      "pytorch_model.bin:   6%|█▏                  | 325M/5.30G [00:08<01:58, 42.2MB/s]\u001b[A\n",
      "pytorch_model.bin:   6%|█▎                  | 336M/5.30G [00:08<01:44, 47.7MB/s]\u001b[A\n",
      "pytorch_model.bin:   7%|█▎                  | 346M/5.30G [00:08<01:48, 45.9MB/s]\u001b[A\n",
      "pytorch_model.bin:   7%|█▎                  | 357M/5.30G [00:08<01:34, 52.6MB/s]\u001b[A\n",
      "pytorch_model.bin:   7%|█▍                  | 367M/5.30G [00:09<01:39, 49.5MB/s]\u001b[A\n",
      "pytorch_model.bin:   7%|█▍                  | 377M/5.30G [00:09<01:30, 54.4MB/s]\u001b[A\n",
      "pytorch_model.bin:   7%|█▍                  | 388M/5.30G [00:09<01:27, 56.3MB/s]\u001b[A\n",
      "pytorch_model.bin:   8%|█▌                  | 398M/5.30G [00:09<02:29, 32.8MB/s]\u001b[A\n",
      "pytorch_model.bin:   8%|█▌                  | 409M/5.30G [00:10<02:35, 31.5MB/s]\u001b[A\n",
      "pytorch_model.bin:   8%|█▌                  | 419M/5.30G [00:10<02:21, 34.4MB/s]\u001b[A\n",
      "pytorch_model.bin:   8%|█▌                  | 430M/5.30G [00:10<01:55, 42.1MB/s]\u001b[A\n",
      "pytorch_model.bin:   8%|█▋                  | 440M/5.30G [00:10<01:37, 49.9MB/s]\u001b[A\n",
      "pytorch_model.bin:   9%|█▋                  | 451M/5.30G [00:11<02:35, 31.3MB/s]\u001b[A\n",
      "pytorch_model.bin:   9%|█▋                  | 461M/5.30G [00:11<02:09, 37.4MB/s]\u001b[A\n",
      "pytorch_model.bin:   9%|█▊                  | 472M/5.30G [00:12<02:34, 31.4MB/s]\u001b[A\n",
      "pytorch_model.bin:   9%|█▊                  | 482M/5.30G [00:12<02:06, 38.0MB/s]\u001b[A\n",
      "pytorch_model.bin:   9%|█▊                  | 493M/5.30G [00:12<01:49, 44.1MB/s]\u001b[A\n",
      "pytorch_model.bin:   9%|█▉                  | 503M/5.30G [00:13<02:51, 28.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  10%|█▉                  | 514M/5.30G [00:13<02:21, 33.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  10%|█▉                  | 524M/5.30G [00:13<02:47, 28.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  10%|██                  | 535M/5.30G [00:13<02:13, 35.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  10%|██                  | 545M/5.30G [00:13<01:50, 43.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  10%|██                  | 556M/5.30G [00:14<02:39, 29.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  11%|██▏                 | 566M/5.30G [00:14<02:09, 36.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  11%|██▏                 | 577M/5.30G [00:15<02:26, 32.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  11%|██▏                 | 587M/5.30G [00:15<02:22, 33.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  11%|██▎                 | 598M/5.30G [00:15<02:02, 38.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  11%|██▎                 | 608M/5.30G [00:16<02:59, 26.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  12%|██▎                 | 619M/5.30G [00:16<02:21, 33.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  12%|██▎                 | 629M/5.30G [00:16<02:27, 31.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  12%|██▍                 | 640M/5.30G [00:16<02:04, 37.5MB/s]\u001b[A\n",
      "Fetching 7 files:  29%|███████▋                   | 2/7 [00:18<00:00, 10.30it/s]\u001b[A\n",
      "pytorch_model.bin:  12%|██▍                 | 661M/5.30G [00:18<03:34, 21.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  13%|██▌                 | 671M/5.30G [00:18<02:47, 27.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  13%|██▌                 | 682M/5.30G [00:18<03:26, 22.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  13%|██▌                 | 692M/5.30G [00:19<02:52, 26.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  13%|██▋                 | 703M/5.30G [00:19<02:16, 33.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  13%|██▋                 | 713M/5.30G [00:19<03:10, 24.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  14%|██▋                 | 724M/5.30G [00:20<02:28, 30.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  14%|██▊                 | 734M/5.30G [00:21<03:51, 19.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  14%|██▊                 | 744M/5.30G [00:21<03:04, 24.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  14%|██▊                 | 755M/5.30G [00:21<02:31, 30.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  14%|██▉                 | 765M/5.30G [00:21<02:36, 29.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  15%|██▉                 | 776M/5.30G [00:21<02:04, 36.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  15%|██▉                 | 786M/5.30G [00:22<02:28, 30.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  15%|███                 | 797M/5.30G [00:22<02:07, 35.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  15%|███                 | 807M/5.30G [00:22<01:51, 40.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  15%|███                 | 818M/5.30G [00:22<01:38, 45.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  16%|███                 | 828M/5.30G [00:23<01:26, 51.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  16%|███▏                | 839M/5.30G [00:23<01:41, 44.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  16%|███▏                | 849M/5.30G [00:23<01:38, 45.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  16%|███▏                | 860M/5.30G [00:23<01:23, 53.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  16%|███▎                | 870M/5.30G [00:23<01:27, 50.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  17%|███▎                | 881M/5.30G [00:24<01:16, 58.1MB/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin:  17%|███▎                | 891M/5.30G [00:24<02:33, 28.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  17%|███▍                | 902M/5.30G [00:25<02:14, 32.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  17%|███▍                | 912M/5.30G [00:25<01:57, 37.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  17%|███▍                | 923M/5.30G [00:26<03:05, 23.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  18%|███▌                | 933M/5.30G [00:26<02:25, 30.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  18%|███▌                | 944M/5.30G [00:26<02:09, 33.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  18%|███▌                | 954M/5.30G [00:26<01:59, 36.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  18%|███▋                | 965M/5.30G [00:26<01:38, 44.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  18%|███▋                | 975M/5.30G [00:27<02:36, 27.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  19%|███▋                | 986M/5.30G [00:27<02:12, 32.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  19%|███▊                | 996M/5.30G [00:27<01:46, 40.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  19%|███▌               | 1.01G/5.30G [00:27<01:31, 46.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  19%|███▋               | 1.02G/5.30G [00:28<01:22, 51.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  19%|███▋               | 1.03G/5.30G [00:28<01:34, 45.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  20%|███▋               | 1.04G/5.30G [00:28<01:25, 49.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  20%|███▊               | 1.05G/5.30G [00:29<02:12, 32.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  20%|███▊               | 1.06G/5.30G [00:29<02:14, 31.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  20%|███▊               | 1.07G/5.30G [00:29<01:49, 38.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  20%|███▊               | 1.08G/5.30G [00:30<02:37, 26.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  21%|███▉               | 1.09G/5.30G [00:30<02:04, 33.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  21%|███▉               | 1.10G/5.30G [00:30<01:43, 40.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  21%|███▉               | 1.11G/5.30G [00:30<01:42, 41.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  21%|████               | 1.12G/5.30G [00:30<01:26, 48.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  21%|████               | 1.13G/5.30G [00:31<02:06, 33.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  22%|████               | 1.14G/5.30G [00:31<01:47, 38.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  22%|████▏              | 1.15G/5.30G [00:31<01:47, 38.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  22%|████▏              | 1.16G/5.30G [00:32<01:31, 45.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  22%|████▏              | 1.17G/5.30G [00:32<01:21, 50.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  22%|████▏              | 1.18G/5.30G [00:32<02:00, 34.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  23%|████▎              | 1.20G/5.30G [00:32<01:37, 42.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  23%|████▎              | 1.21G/5.30G [00:33<01:47, 38.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  23%|████▎              | 1.22G/5.30G [00:33<01:29, 45.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  23%|████▍              | 1.23G/5.30G [00:33<01:17, 52.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  23%|████▍              | 1.24G/5.30G [00:33<01:47, 37.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  24%|████▍              | 1.25G/5.30G [00:34<01:30, 44.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  24%|████▌              | 1.26G/5.30G [00:34<02:03, 32.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  24%|████▌              | 1.27G/5.30G [00:34<01:48, 37.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  24%|████▌              | 1.28G/5.30G [00:34<01:29, 44.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  24%|████▌              | 1.29G/5.30G [00:35<01:31, 43.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  25%|████▋              | 1.30G/5.30G [00:35<01:16, 52.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  25%|████▋              | 1.31G/5.30G [00:35<01:20, 49.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  25%|████▋              | 1.32G/5.30G [00:35<01:12, 54.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  25%|████▊              | 1.33G/5.30G [00:35<01:08, 58.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  25%|████▊              | 1.34G/5.30G [00:36<02:24, 27.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  26%|████▊              | 1.35G/5.30G [00:36<01:56, 33.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  26%|████▉              | 1.36G/5.30G [00:37<01:47, 36.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  26%|████▉              | 1.37G/5.30G [00:37<01:39, 39.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  26%|████▉              | 1.38G/5.30G [00:37<01:24, 46.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  26%|████▉              | 1.39G/5.30G [00:38<02:19, 28.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  26%|█████              | 1.41G/5.30G [00:38<01:50, 35.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  27%|█████              | 1.42G/5.30G [00:38<01:53, 34.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  27%|█████              | 1.43G/5.30G [00:38<01:33, 41.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  27%|█████▏             | 1.44G/5.30G [00:38<01:23, 46.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  27%|█████▏             | 1.45G/5.30G [00:39<02:01, 31.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  27%|█████▏             | 1.46G/5.30G [00:39<01:39, 38.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  28%|█████▎             | 1.47G/5.30G [00:40<02:29, 25.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  28%|█████▎             | 1.48G/5.30G [00:40<02:01, 31.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  28%|█████▎             | 1.49G/5.30G [00:40<01:48, 35.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  28%|█████▎             | 1.50G/5.30G [00:41<02:07, 29.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  28%|█████▍             | 1.51G/5.30G [00:41<01:41, 37.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  29%|█████▍             | 1.52G/5.30G [00:41<01:42, 36.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  29%|█████▍             | 1.53G/5.30G [00:41<01:24, 44.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  29%|█████▌             | 1.54G/5.30G [00:41<01:15, 49.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  29%|█████▌             | 1.55G/5.30G [00:42<02:17, 27.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  29%|█████▌             | 1.56G/5.30G [00:42<01:47, 34.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  30%|█████▋             | 1.57G/5.30G [00:43<01:57, 31.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  30%|█████▋             | 1.58G/5.30G [00:43<01:36, 38.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  30%|█████▋             | 1.59G/5.30G [00:43<01:25, 43.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  30%|█████▋             | 1.60G/5.30G [00:43<01:35, 38.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  30%|█████▊             | 1.61G/5.30G [00:44<01:51, 33.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  31%|█████▊             | 1.63G/5.30G [00:44<02:30, 24.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  31%|█████▊             | 1.64G/5.30G [00:45<02:09, 28.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  31%|█████▉             | 1.65G/5.30G [00:45<01:45, 34.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  31%|█████▉             | 1.66G/5.30G [00:45<01:41, 35.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  31%|█████▉             | 1.67G/5.30G [00:45<01:25, 42.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  32%|██████             | 1.68G/5.30G [00:46<01:56, 31.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  32%|██████             | 1.69G/5.30G [00:46<01:39, 36.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  32%|██████             | 1.70G/5.30G [00:46<01:23, 43.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  32%|██████             | 1.71G/5.30G [00:46<01:26, 41.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  32%|██████▏            | 1.72G/5.30G [00:46<01:14, 48.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  33%|██████▏            | 1.73G/5.30G [00:47<01:20, 44.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  33%|██████▏            | 1.74G/5.30G [00:47<01:10, 50.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  33%|██████▎            | 1.75G/5.30G [00:47<01:04, 55.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  33%|██████▎            | 1.76G/5.30G [00:47<01:16, 46.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  33%|██████▎            | 1.77G/5.30G [00:47<01:06, 53.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  34%|██████▍            | 1.78G/5.30G [00:48<01:44, 33.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  34%|██████▍            | 1.79G/5.30G [00:48<01:31, 38.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  34%|██████▍            | 1.80G/5.30G [00:48<01:14, 46.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  34%|██████▍            | 1.81G/5.30G [00:49<01:37, 36.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  34%|██████▌            | 1.82G/5.30G [00:49<01:20, 43.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  35%|██████▌            | 1.84G/5.30G [00:49<01:56, 29.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  35%|██████▌            | 1.85G/5.30G [00:50<01:38, 35.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  35%|██████▋            | 1.86G/5.30G [00:50<01:20, 42.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  35%|██████▋            | 1.87G/5.30G [00:50<01:12, 47.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  35%|██████▋            | 1.88G/5.30G [00:50<01:04, 52.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  36%|██████▊            | 1.89G/5.30G [00:51<01:55, 29.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  36%|██████▊            | 1.90G/5.30G [00:51<01:36, 35.3MB/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin:  36%|██████▊            | 1.91G/5.30G [00:51<01:19, 42.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  36%|██████▊            | 1.92G/5.30G [00:52<01:39, 33.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  36%|██████▉            | 1.93G/5.30G [00:52<01:23, 40.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  37%|██████▉            | 1.94G/5.30G [00:52<01:24, 39.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  37%|██████▉            | 1.95G/5.30G [00:52<01:17, 43.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  37%|███████            | 1.96G/5.30G [00:52<01:06, 50.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  37%|███████            | 1.97G/5.30G [00:53<01:38, 33.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  37%|███████            | 1.98G/5.30G [00:53<01:23, 39.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  38%|███████▏           | 1.99G/5.30G [00:53<01:28, 37.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  38%|███████▏           | 2.00G/5.30G [00:54<01:30, 36.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  38%|███████▏           | 2.01G/5.30G [00:54<01:24, 39.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  38%|███████▎           | 2.02G/5.30G [00:54<01:49, 29.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  38%|███████▎           | 2.03G/5.30G [00:55<01:36, 33.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  39%|███████▎           | 2.04G/5.30G [00:55<02:10, 25.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  39%|███████▎           | 2.06G/5.30G [00:55<01:41, 32.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  39%|███████▍           | 2.07G/5.30G [00:56<01:22, 39.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  39%|███████▍           | 2.08G/5.30G [00:56<01:33, 34.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  39%|███████▍           | 2.09G/5.30G [00:56<01:21, 39.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  40%|███████▌           | 2.10G/5.30G [00:57<01:57, 27.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  40%|███████▌           | 2.11G/5.30G [00:57<01:40, 31.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  40%|███████▌           | 2.12G/5.30G [00:57<01:22, 38.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  40%|███████▋           | 2.13G/5.30G [00:58<02:03, 25.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  40%|███████▋           | 2.14G/5.30G [00:58<01:35, 33.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  41%|███████▋           | 2.15G/5.30G [00:58<01:40, 31.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  41%|███████▋           | 2.16G/5.30G [00:58<01:27, 36.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  41%|███████▊           | 2.17G/5.30G [00:59<01:30, 34.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  41%|███████▊           | 2.18G/5.30G [00:59<01:51, 28.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  41%|███████▊           | 2.19G/5.30G [00:59<01:29, 34.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  42%|███████▉           | 2.20G/5.30G [01:00<01:36, 32.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  42%|███████▉           | 2.21G/5.30G [01:00<01:22, 37.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  42%|███████▉           | 2.22G/5.30G [01:00<01:27, 35.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  42%|████████           | 2.23G/5.30G [01:01<02:17, 22.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  42%|████████           | 2.24G/5.30G [01:01<01:54, 26.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  43%|████████           | 2.25G/5.30G [01:02<01:55, 26.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  43%|████████           | 2.26G/5.30G [01:02<01:34, 32.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  43%|████████▏          | 2.28G/5.30G [01:02<01:15, 39.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  43%|████████▏          | 2.29G/5.30G [01:03<01:33, 32.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  43%|████████▏          | 2.30G/5.30G [01:03<01:38, 30.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  43%|████████▎          | 2.31G/5.30G [01:04<01:58, 25.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  44%|████████▎          | 2.32G/5.30G [01:04<01:33, 32.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  44%|████████▎          | 2.33G/5.30G [01:04<01:15, 39.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  44%|████████▍          | 2.34G/5.30G [01:04<01:40, 29.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  44%|████████▍          | 2.35G/5.30G [01:05<01:19, 37.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  44%|████████▍          | 2.36G/5.30G [01:05<01:36, 30.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  45%|████████▍          | 2.37G/5.30G [01:05<01:35, 30.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  45%|████████▌          | 2.38G/5.30G [01:05<01:18, 37.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  45%|████████▌          | 2.39G/5.30G [01:06<01:59, 24.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  45%|████████▌          | 2.40G/5.30G [01:06<01:36, 29.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  45%|████████▋          | 2.41G/5.30G [01:07<01:47, 27.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  46%|████████▋          | 2.42G/5.30G [01:07<01:37, 29.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  46%|████████▋          | 2.43G/5.30G [01:07<01:21, 35.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  46%|████████▊          | 2.44G/5.30G [01:08<02:04, 22.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  46%|████████▊          | 2.45G/5.30G [01:08<01:37, 29.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  46%|████████▊          | 2.46G/5.30G [01:09<02:17, 20.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  47%|████████▊          | 2.47G/5.30G [01:09<01:49, 25.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  47%|████████▉          | 2.49G/5.30G [01:09<01:25, 32.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  47%|████████▉          | 2.50G/5.30G [01:10<01:19, 35.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  47%|████████▉          | 2.51G/5.30G [01:10<01:05, 42.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  47%|█████████          | 2.52G/5.30G [01:10<01:14, 37.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  48%|█████████          | 2.53G/5.30G [01:10<01:13, 37.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  48%|█████████          | 2.54G/5.30G [01:11<01:27, 31.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  48%|█████████▏         | 2.55G/5.30G [01:11<01:45, 26.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  48%|█████████▏         | 2.56G/5.30G [01:12<01:30, 30.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  48%|█████████▏         | 2.57G/5.30G [01:12<01:45, 25.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  49%|█████████▏         | 2.58G/5.30G [01:13<01:38, 27.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  49%|█████████▎         | 2.59G/5.30G [01:13<01:20, 33.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  49%|█████████▎         | 2.60G/5.30G [01:13<01:40, 27.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  49%|█████████▎         | 2.61G/5.30G [01:13<01:20, 33.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  49%|█████████▍         | 2.62G/5.30G [01:14<01:31, 29.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  50%|█████████▍         | 2.63G/5.30G [01:14<01:16, 35.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  50%|█████████▍         | 2.64G/5.30G [01:14<01:04, 41.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  50%|█████████▌         | 2.65G/5.30G [01:15<01:41, 26.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  50%|█████████▌         | 2.66G/5.30G [01:15<01:19, 33.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  50%|█████████▌         | 2.67G/5.30G [01:16<01:45, 24.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  51%|█████████▌         | 2.68G/5.30G [01:16<01:25, 30.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  51%|█████████▋         | 2.69G/5.30G [01:16<01:08, 38.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  51%|█████████▋         | 2.71G/5.30G [01:17<01:27, 29.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  51%|█████████▋         | 2.72G/5.30G [01:17<01:10, 36.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  51%|█████████▊         | 2.73G/5.30G [01:17<01:02, 41.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  52%|█████████▊         | 2.74G/5.30G [01:17<00:57, 44.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  52%|█████████▊         | 2.75G/5.30G [01:17<00:50, 50.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  52%|█████████▉         | 2.76G/5.30G [01:18<01:07, 37.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  52%|█████████▉         | 2.77G/5.30G [01:18<00:58, 43.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  52%|█████████▉         | 2.78G/5.30G [01:18<01:24, 29.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  53%|█████████▉         | 2.79G/5.30G [01:19<01:10, 35.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  53%|██████████         | 2.80G/5.30G [01:19<00:59, 42.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  53%|██████████         | 2.81G/5.30G [01:19<00:56, 44.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  53%|██████████         | 2.82G/5.30G [01:19<00:47, 51.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  53%|██████████▏        | 2.83G/5.30G [01:20<01:11, 34.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  54%|██████████▏        | 2.84G/5.30G [01:20<01:06, 37.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  54%|██████████▏        | 2.85G/5.30G [01:20<00:57, 42.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  54%|██████████▎        | 2.86G/5.30G [01:20<01:03, 38.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  54%|██████████▎        | 2.87G/5.30G [01:21<01:12, 33.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  54%|██████████▎        | 2.88G/5.30G [01:21<01:19, 30.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  55%|██████████▎        | 2.89G/5.30G [01:21<01:04, 37.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  55%|██████████▍        | 2.90G/5.30G [01:22<01:14, 32.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  55%|██████████▍        | 2.92G/5.30G [01:22<01:40, 23.8MB/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin:  55%|██████████▍        | 2.93G/5.30G [01:23<01:25, 27.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  55%|██████████▌        | 2.94G/5.30G [01:23<02:00, 19.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  56%|██████████▌        | 2.95G/5.30G [01:24<01:35, 24.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  56%|██████████▌        | 2.96G/5.30G [01:24<01:20, 29.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  56%|██████████▋        | 2.97G/5.30G [01:25<01:49, 21.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  56%|██████████▋        | 2.98G/5.30G [01:25<01:26, 27.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  56%|██████████▋        | 2.99G/5.30G [01:25<01:39, 23.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  57%|██████████▋        | 3.00G/5.30G [01:26<01:18, 29.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  57%|██████████▊        | 3.01G/5.30G [01:26<01:03, 36.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  57%|██████████▊        | 3.02G/5.30G [01:26<01:01, 37.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  57%|██████████▊        | 3.03G/5.30G [01:26<00:51, 44.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  57%|██████████▉        | 3.04G/5.30G [01:27<01:16, 29.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  58%|██████████▉        | 3.05G/5.30G [01:27<01:00, 37.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  58%|██████████▉        | 3.06G/5.30G [01:27<00:52, 43.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  58%|███████████        | 3.07G/5.30G [01:27<01:04, 34.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  58%|███████████        | 3.08G/5.30G [01:28<00:53, 41.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  58%|███████████        | 3.09G/5.30G [01:28<01:23, 26.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  59%|███████████        | 3.10G/5.30G [01:28<01:06, 32.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  59%|███████████▏       | 3.11G/5.30G [01:29<01:06, 32.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  59%|███████████▏       | 3.12G/5.30G [01:29<01:08, 31.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  59%|███████████▏       | 3.14G/5.30G [01:29<01:01, 35.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  59%|███████████▎       | 3.15G/5.30G [01:30<01:02, 34.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  60%|███████████▎       | 3.16G/5.30G [01:30<00:52, 40.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  60%|███████████▎       | 3.17G/5.30G [01:30<00:43, 49.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  60%|███████████▍       | 3.18G/5.30G [01:31<01:14, 28.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  60%|███████████▍       | 3.19G/5.30G [01:31<01:00, 35.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  60%|███████████▍       | 3.20G/5.30G [01:31<01:17, 27.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  61%|███████████▍       | 3.21G/5.30G [01:31<01:01, 33.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  61%|███████████▌       | 3.22G/5.30G [01:32<00:49, 41.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  61%|███████████▌       | 3.23G/5.30G [01:32<01:06, 31.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  61%|███████████▌       | 3.24G/5.30G [01:32<00:54, 37.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  61%|███████████▋       | 3.25G/5.30G [01:33<01:03, 32.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  61%|███████████▋       | 3.26G/5.30G [01:33<00:55, 37.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  62%|███████████▋       | 3.27G/5.30G [01:33<00:45, 45.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  62%|███████████▊       | 3.28G/5.30G [01:34<01:17, 26.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  62%|███████████▊       | 3.29G/5.30G [01:34<01:01, 32.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  62%|███████████▊       | 3.30G/5.30G [01:35<01:28, 22.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  62%|███████████▊       | 3.31G/5.30G [01:35<01:23, 24.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  63%|███████████▉       | 3.32G/5.30G [01:35<01:04, 30.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  63%|███████████▉       | 3.33G/5.30G [01:36<01:14, 26.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  63%|███████████▉       | 3.34G/5.30G [01:36<01:00, 32.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  63%|████████████       | 3.36G/5.30G [01:36<00:57, 34.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  63%|████████████       | 3.37G/5.30G [01:36<00:50, 38.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  64%|████████████       | 3.38G/5.30G [01:36<00:43, 44.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  64%|████████████▏      | 3.39G/5.30G [01:37<01:09, 27.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  64%|████████████▏      | 3.40G/5.30G [01:37<00:55, 34.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  64%|████████████▏      | 3.41G/5.30G [01:38<00:50, 37.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  64%|████████████▏      | 3.42G/5.30G [01:38<00:44, 42.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  65%|████████████▎      | 3.43G/5.30G [01:38<00:37, 50.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  65%|████████████▎      | 3.44G/5.30G [01:38<00:45, 41.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  65%|████████████▎      | 3.45G/5.30G [01:38<00:39, 47.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  65%|████████████▍      | 3.46G/5.30G [01:39<01:08, 26.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  65%|████████████▍      | 3.47G/5.30G [01:39<00:55, 33.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  66%|████████████▍      | 3.48G/5.30G [01:39<00:46, 38.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  66%|████████████▌      | 3.49G/5.30G [01:40<01:05, 27.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  66%|████████████▌      | 3.50G/5.30G [01:40<00:52, 34.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  66%|████████████▌      | 3.51G/5.30G [01:41<01:20, 22.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  66%|████████████▌      | 3.52G/5.30G [01:41<01:04, 27.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  67%|████████████▋      | 3.53G/5.30G [01:41<00:51, 34.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  67%|████████████▋      | 3.54G/5.30G [01:42<01:01, 28.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  67%|████████████▋      | 3.55G/5.30G [01:42<00:48, 36.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  67%|████████████▊      | 3.57G/5.30G [01:42<00:48, 35.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  67%|████████████▊      | 3.58G/5.30G [01:43<00:45, 37.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  68%|████████████▊      | 3.59G/5.30G [01:43<00:39, 44.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  68%|████████████▉      | 3.60G/5.30G [01:44<01:13, 23.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  68%|████████████▉      | 3.61G/5.30G [01:44<00:56, 29.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  68%|████████████▉      | 3.62G/5.30G [01:44<00:53, 31.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  68%|████████████▉      | 3.63G/5.30G [01:44<00:43, 38.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  69%|█████████████      | 3.64G/5.30G [01:44<00:36, 45.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  69%|█████████████      | 3.65G/5.30G [01:45<00:50, 32.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  69%|█████████████      | 3.66G/5.30G [01:45<00:41, 39.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  69%|█████████████▏     | 3.67G/5.30G [01:45<00:49, 33.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  69%|█████████████▏     | 3.68G/5.30G [01:46<00:39, 41.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  70%|█████████████▏     | 3.69G/5.30G [01:46<00:33, 47.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  70%|█████████████▎     | 3.70G/5.30G [01:47<01:02, 25.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  70%|█████████████▎     | 3.71G/5.30G [01:47<00:49, 31.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  70%|█████████████▎     | 3.72G/5.30G [01:47<00:56, 28.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  70%|█████████████▎     | 3.73G/5.30G [01:47<00:46, 33.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  71%|█████████████▍     | 3.74G/5.30G [01:47<00:38, 40.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  71%|█████████████▍     | 3.75G/5.30G [01:48<00:37, 40.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  71%|█████████████▍     | 3.76G/5.30G [01:48<00:32, 46.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  71%|█████████████▌     | 3.77G/5.30G [01:48<00:28, 53.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  71%|█████████████▌     | 3.79G/5.30G [01:48<00:26, 56.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  72%|█████████████▌     | 3.80G/5.30G [01:48<00:24, 60.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  72%|█████████████▋     | 3.81G/5.30G [01:49<00:43, 34.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  72%|█████████████▋     | 3.82G/5.30G [01:49<00:35, 41.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  72%|█████████████▋     | 3.83G/5.30G [01:49<00:36, 40.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  72%|█████████████▋     | 3.84G/5.30G [01:49<00:30, 47.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  73%|█████████████▊     | 3.85G/5.30G [01:50<00:27, 52.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  73%|█████████████▊     | 3.86G/5.30G [01:50<00:30, 48.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  73%|█████████████▊     | 3.87G/5.30G [01:50<00:26, 54.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  73%|█████████████▉     | 3.88G/5.30G [01:51<00:44, 31.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  73%|█████████████▉     | 3.89G/5.30G [01:51<00:38, 37.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  74%|█████████████▉     | 3.90G/5.30G [01:51<00:31, 44.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  74%|██████████████     | 3.91G/5.30G [01:51<00:37, 36.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  74%|██████████████     | 3.92G/5.30G [01:51<00:32, 43.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  74%|██████████████     | 3.93G/5.30G [01:52<00:33, 41.4MB/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin:  74%|██████████████▏    | 3.94G/5.30G [01:52<00:30, 45.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  75%|██████████████▏    | 3.95G/5.30G [01:52<00:26, 51.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  75%|██████████████▏    | 3.96G/5.30G [01:53<00:57, 23.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  75%|██████████████▏    | 3.97G/5.30G [01:53<00:44, 29.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  75%|██████████████▎    | 3.98G/5.30G [01:54<00:49, 26.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  75%|██████████████▎    | 4.00G/5.30G [01:54<00:46, 28.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  76%|██████████████▎    | 4.01G/5.30G [01:54<00:36, 35.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  76%|██████████████▍    | 4.02G/5.30G [01:55<00:47, 26.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  76%|██████████████▍    | 4.03G/5.30G [01:55<00:37, 34.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  76%|██████████████▍    | 4.04G/5.30G [01:55<00:39, 31.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  76%|██████████████▌    | 4.05G/5.30G [01:55<00:32, 38.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  77%|██████████████▌    | 4.06G/5.30G [01:56<00:27, 44.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  77%|██████████████▌    | 4.07G/5.30G [01:56<00:30, 40.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  77%|██████████████▌    | 4.08G/5.30G [01:56<00:29, 40.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  77%|██████████████▋    | 4.09G/5.30G [01:57<00:47, 25.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  77%|██████████████▋    | 4.10G/5.30G [01:57<00:41, 28.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  78%|██████████████▋    | 4.11G/5.30G [01:57<00:33, 35.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  78%|██████████████▊    | 4.12G/5.30G [01:58<00:40, 29.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  78%|██████████████▊    | 4.13G/5.30G [01:58<00:32, 35.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  78%|██████████████▊    | 4.14G/5.30G [01:59<00:49, 23.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  78%|██████████████▉    | 4.15G/5.30G [01:59<00:39, 29.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  78%|██████████████▉    | 4.16G/5.30G [01:59<00:32, 35.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  79%|██████████████▉    | 4.17G/5.30G [01:59<00:30, 37.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  79%|██████████████▉    | 4.18G/5.30G [01:59<00:25, 44.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  79%|███████████████    | 4.19G/5.30G [02:00<00:26, 41.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  79%|███████████████    | 4.20G/5.30G [02:00<00:22, 48.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  79%|███████████████    | 4.22G/5.30G [02:00<00:19, 55.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  80%|███████████████▏   | 4.23G/5.30G [02:00<00:25, 41.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  80%|███████████████▏   | 4.24G/5.30G [02:00<00:21, 50.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  80%|███████████████▏   | 4.25G/5.30G [02:01<00:28, 36.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  80%|███████████████▎   | 4.26G/5.30G [02:01<00:24, 43.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  80%|███████████████▎   | 4.27G/5.30G [02:01<00:19, 52.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  81%|███████████████▎   | 4.28G/5.30G [02:02<00:26, 39.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  81%|███████████████▎   | 4.29G/5.30G [02:02<00:21, 47.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  81%|███████████████▍   | 4.30G/5.30G [02:02<00:25, 38.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  81%|███████████████▍   | 4.31G/5.30G [02:02<00:22, 44.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  81%|███████████████▍   | 4.32G/5.30G [02:02<00:19, 50.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  82%|███████████████▌   | 4.33G/5.30G [02:03<00:25, 38.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  82%|███████████████▌   | 4.34G/5.30G [02:03<00:20, 46.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  82%|███████████████▌   | 4.35G/5.30G [02:04<00:30, 31.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  82%|███████████████▋   | 4.36G/5.30G [02:04<00:26, 36.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  82%|███████████████▋   | 4.37G/5.30G [02:04<00:22, 41.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  83%|███████████████▋   | 4.38G/5.30G [02:04<00:22, 41.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  83%|███████████████▋   | 4.39G/5.30G [02:04<00:20, 43.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  83%|███████████████▊   | 4.40G/5.30G [02:05<00:30, 29.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  83%|███████████████▊   | 4.41G/5.30G [02:05<00:27, 32.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  83%|███████████████▊   | 4.42G/5.30G [02:05<00:21, 40.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  84%|███████████████▉   | 4.44G/5.30G [02:06<00:31, 27.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  84%|███████████████▉   | 4.45G/5.30G [02:06<00:24, 35.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  84%|███████████████▉   | 4.46G/5.30G [02:06<00:23, 36.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  84%|████████████████   | 4.47G/5.30G [02:07<00:21, 38.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  84%|████████████████   | 4.48G/5.30G [02:07<00:17, 46.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  85%|████████████████   | 4.49G/5.30G [02:07<00:29, 28.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  85%|████████████████   | 4.50G/5.30G [02:08<00:23, 34.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  85%|████████████████▏  | 4.51G/5.30G [02:08<00:27, 28.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  85%|████████████████▏  | 4.52G/5.30G [02:08<00:25, 31.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  85%|████████████████▏  | 4.53G/5.30G [02:08<00:20, 37.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  86%|████████████████▎  | 4.54G/5.30G [02:09<00:20, 36.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  86%|████████████████▎  | 4.55G/5.30G [02:09<00:17, 42.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  86%|████████████████▎  | 4.56G/5.30G [02:10<00:27, 26.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  86%|████████████████▍  | 4.57G/5.30G [02:10<00:23, 31.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  86%|████████████████▍  | 4.58G/5.30G [02:10<00:18, 39.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  87%|████████████████▍  | 4.59G/5.30G [02:10<00:19, 37.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  87%|████████████████▍  | 4.60G/5.30G [02:10<00:16, 42.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  87%|████████████████▌  | 4.61G/5.30G [02:11<00:24, 28.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  87%|████████████████▌  | 4.62G/5.30G [02:11<00:20, 33.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  87%|████████████████▌  | 4.63G/5.30G [02:11<00:15, 42.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  88%|████████████████▋  | 4.65G/5.30G [02:12<00:24, 26.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  88%|████████████████▋  | 4.66G/5.30G [02:12<00:19, 33.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  88%|████████████████▋  | 4.67G/5.30G [02:13<00:26, 23.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  88%|████████████████▊  | 4.68G/5.30G [02:13<00:20, 29.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  88%|████████████████▊  | 4.69G/5.30G [02:13<00:16, 37.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  89%|████████████████▊  | 4.70G/5.30G [02:14<00:20, 29.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  89%|████████████████▊  | 4.71G/5.30G [02:14<00:16, 35.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  89%|████████████████▉  | 4.72G/5.30G [02:15<00:24, 23.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  89%|████████████████▉  | 4.73G/5.30G [02:15<00:19, 29.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  89%|████████████████▉  | 4.74G/5.30G [02:15<00:15, 36.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  90%|█████████████████  | 4.75G/5.30G [02:15<00:15, 36.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  90%|█████████████████  | 4.76G/5.30G [02:15<00:12, 44.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  90%|█████████████████  | 4.77G/5.30G [02:16<00:17, 30.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  90%|█████████████████▏ | 4.78G/5.30G [02:16<00:14, 35.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  90%|█████████████████▏ | 4.79G/5.30G [02:16<00:11, 43.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  91%|█████████████████▏ | 4.80G/5.30G [02:17<00:15, 32.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  91%|█████████████████▏ | 4.81G/5.30G [02:17<00:12, 39.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  91%|█████████████████▎ | 4.82G/5.30G [02:17<00:15, 31.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  91%|█████████████████▎ | 4.83G/5.30G [02:18<00:13, 35.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  91%|█████████████████▎ | 4.84G/5.30G [02:18<00:12, 37.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  92%|█████████████████▍ | 4.85G/5.30G [02:19<00:18, 23.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  92%|█████████████████▍ | 4.87G/5.30G [02:19<00:14, 30.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  92%|█████████████████▍ | 4.88G/5.30G [02:19<00:17, 25.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  92%|█████████████████▌ | 4.89G/5.30G [02:20<00:13, 30.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  92%|█████████████████▌ | 4.90G/5.30G [02:20<00:11, 36.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  93%|█████████████████▌ | 4.91G/5.30G [02:20<00:14, 27.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  93%|█████████████████▌ | 4.92G/5.30G [02:20<00:11, 34.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  93%|█████████████████▋ | 4.93G/5.30G [02:21<00:12, 28.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  93%|█████████████████▋ | 4.94G/5.30G [02:21<00:10, 33.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  93%|█████████████████▋ | 4.95G/5.30G [02:21<00:08, 39.5MB/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pytorch_model.bin:  94%|█████████████████▊ | 4.96G/5.30G [02:22<00:13, 24.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  94%|█████████████████▊ | 4.97G/5.30G [02:22<00:10, 31.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  94%|█████████████████▊ | 4.98G/5.30G [02:23<00:11, 27.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  94%|█████████████████▉ | 4.99G/5.30G [02:23<00:09, 32.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  94%|█████████████████▉ | 5.00G/5.30G [02:23<00:07, 37.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  95%|█████████████████▉ | 5.01G/5.30G [02:23<00:06, 46.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  95%|█████████████████▉ | 5.02G/5.30G [02:23<00:05, 51.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  95%|██████████████████ | 5.03G/5.30G [02:24<00:05, 52.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  95%|██████████████████ | 5.04G/5.30G [02:24<00:04, 61.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  95%|██████████████████ | 5.05G/5.30G [02:24<00:03, 64.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  95%|██████████████████▏| 5.06G/5.30G [02:24<00:03, 70.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  96%|██████████████████▏| 5.08G/5.30G [02:24<00:03, 71.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  96%|██████████████████▏| 5.09G/5.30G [02:24<00:03, 68.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  96%|██████████████████▎| 5.10G/5.30G [02:24<00:02, 75.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  96%|██████████████████▎| 5.11G/5.30G [02:24<00:02, 75.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  96%|██████████████████▎| 5.12G/5.30G [02:25<00:02, 64.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  97%|██████████████████▎| 5.13G/5.30G [02:25<00:02, 67.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  97%|██████████████████▍| 5.14G/5.30G [02:25<00:02, 65.7MB/s]\u001b[A\n",
      "pytorch_model.bin:  97%|██████████████████▍| 5.15G/5.30G [02:25<00:02, 72.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  97%|██████████████████▍| 5.16G/5.30G [02:25<00:01, 73.5MB/s]\u001b[A\n",
      "pytorch_model.bin:  97%|██████████████████▌| 5.17G/5.30G [02:25<00:01, 79.2MB/s]\u001b[A\n",
      "pytorch_model.bin:  98%|██████████████████▌| 5.18G/5.30G [02:26<00:02, 49.1MB/s]\u001b[A\n",
      "pytorch_model.bin:  98%|██████████████████▌| 5.19G/5.30G [02:26<00:02, 53.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  98%|██████████████████▋| 5.20G/5.30G [02:26<00:02, 49.8MB/s]\u001b[A\n",
      "pytorch_model.bin:  98%|██████████████████▋| 5.21G/5.30G [02:26<00:01, 55.3MB/s]\u001b[A\n",
      "pytorch_model.bin:  98%|██████████████████▋| 5.22G/5.30G [02:26<00:01, 59.6MB/s]\u001b[A\n",
      "pytorch_model.bin:  99%|██████████████████▋| 5.23G/5.30G [02:27<00:01, 52.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  99%|██████████████████▊| 5.24G/5.30G [02:27<00:01, 56.4MB/s]\u001b[A\n",
      "pytorch_model.bin:  99%|██████████████████▊| 5.25G/5.30G [02:27<00:00, 60.0MB/s]\u001b[A\n",
      "pytorch_model.bin:  99%|██████████████████▊| 5.26G/5.30G [02:27<00:01, 36.9MB/s]\u001b[A\n",
      "pytorch_model.bin:  99%|██████████████████▉| 5.27G/5.30G [02:28<00:00, 34.1MB/s]\u001b[A\n",
      "pytorch_model.bin: 100%|██████████████████▉| 5.28G/5.30G [02:28<00:00, 39.9MB/s]\u001b[A\n",
      "pytorch_model.bin: 100%|███████████████████| 5.30G/5.30G [02:28<00:00, 35.7MB/s]\u001b[A\n",
      "Fetching 7 files: 100%|███████████████████████████| 7/7 [02:29<00:00, 21.37s/it]\n"
     ]
    }
   ],
   "source": [
    "llm = openllm.LLM('facebook/opt-2.7b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7ae3e5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-28T02:40:49.452671Z",
     "start_time": "2023-11-28T02:40:49.376428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/openllm/_llm.py\", line 107, in generate_iterator\n",
      "    async for out in generator:\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/openllm/_runners.py\", line 229, in generate_iterator\n",
      "    out = self.model(input_ids=start_ids, use_cache=True)\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/transformers/models/opt/modeling_opt.py\", line 879, in forward\n",
      "    outputs = self.model.decoder(\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/transformers/models/opt/modeling_opt.py\", line 645, in forward\n",
      "    layer_outputs = decoder_layer(\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/transformers/models/opt/modeling_opt.py\", line 296, in forward\n",
      "    hidden_states = self.self_attn_layer_norm(hidden_states)\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/torch/nn/modules/normalization.py\", line 196, in forward\n",
      "    return F.layer_norm(\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/torch/nn/functional.py\", line 2543, in layer_norm\n",
      "    return torch.layer_norm(input, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled)\n",
      "RuntimeError: \"LayerNormKernelImpl\" not implemented for 'Half'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3524, in run_code\n",
      "    await eval(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/g6/s8f0t0ys2rx1j7n5nfjtcp680000gn/T/ipykernel_5435/2116493906.py\", line 1, in <module>\n",
      "    async for generation in llm.generate_iterator('hello. good morning'):\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/openllm/_llm.py\", line 117, in generate_iterator\n",
      "    raise RuntimeError(f'Exception caught during generation: {err}') from err\n",
      "RuntimeError: Exception caught during generation: \"LayerNormKernelImpl\" not implemented for 'Half'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/stack_data/core.py\", line 645, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/stack_data/core.py\", line 585, in scope_pieces\n",
      "    for piece in self.source.pieces\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/stack_data/core.py\", line 90, in pieces\n",
      "    return list(self._clean_pieces())\n",
      "  File \"/Users/indra25/opt/anaconda3/envs/ir_env/lib/python3.9/site-packages/stack_data/core.py\", line 114, in _clean_pieces\n",
      "    raise AssertionError(\"Pieces mismatches: %s\" % mismatches)\n",
      "AssertionError: Pieces mismatches: [{405, 406}]\n"
     ]
    }
   ],
   "source": [
    "async for generation in llm.generate_iterator('hello. good morning'):\n",
    "    print(generation.outputs[0].text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204ca127",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    try:\n",
    "        bot_input = chatbot.get_response(input())\n",
    "        print(bot_input)\n",
    "\n",
    "    except(KeyboardInterrupt, EOFError, SystemExit):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
